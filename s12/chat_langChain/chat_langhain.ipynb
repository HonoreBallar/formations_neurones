{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cad08a2-a2bd-462d-a156-e36ddc7c1637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour Honore !\n"
     ]
    }
   ],
   "source": [
    "print(\"Bonjour Honore !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8fd5b81-9c60-4385-8506-15eee150c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # load environment variables from .env file (requires `python-dotenv`)\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "if \"LANGSMITH_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\n",
    "        prompt=\"Enter your LangSmith API key (optional): \"\n",
    "    )\n",
    "if \"LANGSMITH_PROJECT\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_PROJECT\"] = getpass.getpass(\n",
    "        prompt='Enter your LangSmith Project Name (default = \"default\"): '\n",
    "    )\n",
    "    if not os.environ.get(\"LANGSMITH_PROJECT\"):\n",
    "        os.environ[\"LANGSMITH_PROJECT\"] = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a49e961-422d-42b6-a3a6-7fce071caaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter API key for OpenAI:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7a9ad1b-0e45-437c-87dd-aecea734b669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 20, 'total_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-C8kNSjSXsKYcENgKJCsuvrFtzRQLC', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--a02df46b-079b-481a-8053-cae3b1c4f823-0', usage_metadata={'input_tokens': 20, 'output_tokens': 3, 'total_tokens': 23, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bef47657-9330-415f-b1d3-4ec08886e38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C8kQ0rGkMftTh82I5a005JiLyFW7B', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--f0462769-8394-47b4-bf49-851a53130093-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello\")\n",
    "\n",
    "model.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])\n",
    "\n",
    "model.invoke([HumanMessage(\"Hello\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f751a530-0d58-4d9e-9e8a-f29337b79ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C8kQopxDjMlJrZ7JoMHFwwmFUvVIc', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--1dc50d41-0c1b-464e-81ae-1294c98fa4fc-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello\")\n",
    "\n",
    "model.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])\n",
    "\n",
    "model.invoke([HumanMessage(\"Hello\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f617f56-3572-467c-baca-25ed20cdfd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|C|iao|!||"
     ]
    }
   ],
   "source": [
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13477035-7718-4ed9-a456-c2a859b13d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abc04b14-8714-4884-9ff4-89ed3bccd1d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Mangue' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mMangue\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'Mangue' is not defined"
     ]
    }
   ],
   "source": [
    "Mangue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c26a6f3d-e8c4-48ea-838a-a1c624f1a17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(\"hi!\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)  # Résultat attendu : \"Ciao!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd8e7b64-f53f-41d6-90d5-177cd1154a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"user\", \"{text}\")\n",
    "])\n",
    "\n",
    "prompt = prompt_template.invoke({\n",
    "    \"language\": \"Italian\",\n",
    "    \"text\": \"Hello\"\n",
    "})\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56188607-2f20-4540-8e67-7ddd4229681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57bfe855-0808-42e8-8186-9622c5089d94",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hello' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mhello\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'hello' is not defined"
     ]
    }
   ],
   "source": [
    "hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d426f5d-84b5-4bac-92c9-5b2f0a52490e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi!\"})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d984aa5-a02c-45b2-a3d7-3591ebeb7cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61822322-7ebd-4ab2-bd93-3e96618f54ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao!\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3ffa5c4-dec0-4285-a3ed-e813cbbe1f21",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import langchain_google_genai. Please install with `pip install -U langchain-google-genai`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Initialisation du modèle\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model = \u001b[43minit_chat_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-2.5-flash\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgoogle_genai\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Création du prompt template\u001b[39;00m\n\u001b[32m      9\u001b[39m prompt_template = ChatPromptTemplate.from_messages([\n\u001b[32m     10\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mTranslate the following from English into \u001b[39m\u001b[38;5;132;01m{language}\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m     11\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{text}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m ])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projets/Formation_Neurones/week3/formations_neurones/s12/chat_langChain/venv/lib/python3.12/site-packages/langchain/chat_models/base.py:324\u001b[39m, in \u001b[36minit_chat_model\u001b[39m\u001b[34m(model, model_provider, configurable_fields, config_prefix, **kwargs)\u001b[39m\n\u001b[32m    316\u001b[39m     warnings.warn(\n\u001b[32m    317\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_prefix\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m has been set but no fields are configurable. Set \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    318\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`configurable_fields=(...)` to specify the model params that are \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    319\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconfigurable.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    320\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    321\u001b[39m     )\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m configurable_fields:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_init_chat_model_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model:\n\u001b[32m    330\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projets/Formation_Neurones/week3/formations_neurones/s12/chat_langChain/venv/lib/python3.12/site-packages/langchain/chat_models/base.py:378\u001b[39m, in \u001b[36m_init_chat_model_helper\u001b[39m\u001b[34m(model, model_provider, **kwargs)\u001b[39m\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatVertexAI(model=model, **kwargs)\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_provider == \u001b[33m\"\u001b[39m\u001b[33mgoogle_genai\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     \u001b[43m_check_pkg\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlangchain_google_genai\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[32m    381\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatGoogleGenerativeAI(model=model, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projets/Formation_Neurones/week3/formations_neurones/s12/chat_langChain/venv/lib/python3.12/site-packages/langchain/chat_models/base.py:543\u001b[39m, in \u001b[36m_check_pkg\u001b[39m\u001b[34m(pkg, pkg_kebab)\u001b[39m\n\u001b[32m    539\u001b[39m pkg_kebab = pkg_kebab \u001b[38;5;28;01mif\u001b[39;00m pkg_kebab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pkg.replace(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    540\u001b[39m msg = (\n\u001b[32m    541\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnable to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Please install with `pip install -U \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg_kebab\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    542\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n",
      "\u001b[31mImportError\u001b[39m: Unable to import langchain_google_genai. Please install with `pip install -U langchain-google-genai`"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Initialisation du modèle\n",
    "model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")\n",
    "\n",
    "# Création du prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Translate the following from English into {language}\"),\n",
    "    (\"user\", \"{text}\")\n",
    "])\n",
    "\n",
    "# Formatage du prompt\n",
    "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi!\"})\n",
    "\n",
    "# Appel du modèle\n",
    "response = model.invoke(prompt)\n",
    "print(response.content)  # → \"Ciao!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7092c9d5-c7c1-49dd-9899-4e11aab69ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
